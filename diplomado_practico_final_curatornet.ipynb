{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "diplomado_practico_final_curatornet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hernan4444/Hernan4444-diplomado-sistemas-recomendadores-2020-1/blob/master/diplomado_practico_final_curatornet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7lhj8NuX9TS",
        "colab_type": "text"
      },
      "source": [
        "# Práctico final diplomado Sistemas recomendadores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3HG5pBmeb8v",
        "colab_type": "text"
      },
      "source": [
        "Bienvenidos a la última actividad del curso de Sistemas Recomendadores. En esta oportunidad trabajaremos con un modelo de Deep Learning desarrollado en la PUC, el cual fue diseñado para recomendaro obras de arte a usuarios que hayan realizado compras anteriormente.\n",
        "\n",
        "El trabajo original lo podrás encontrar en el siguiente link: [Content-Based Artwork Recommendation: Integrating Painting Metadata with Neural and Manually-Engineered Visual Features](https://dars.uib.no/pubs/UMUAI2018.pdf).\n",
        "\n",
        "Cabe señalar que en esta actividad utilizaremos una versión simplificada del trabajo original."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjmA2PpIelwc",
        "colab_type": "text"
      },
      "source": [
        "### Instrucciones\n",
        "\n",
        "Este laboratorio se puede realizar en grupos de 2. Es de suma importancia que le coloquen el nombre de los participantes a continuación y que sólo uno de uds. suba el archivo .ipynb a la plataforma del curso.\n",
        "\n",
        "Para completar el laboratorio tendrán que seguir las instrucciones de este _Jupyter Notebook_, contestando a todas las actividades marcadas.\n",
        "\n",
        "**Nombre Integrante #1**:\n",
        "\n",
        "**Nombre Integrante #2**:\n",
        "\n",
        "Recuerden que este laboratorio tiene nota doble.\n",
        "\n",
        "**Importante: Cualquier falta a estas instrucciones tendrá una penalización de 1.0 punto en la nota final.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsNl8VcRaioZ",
        "colab_type": "text"
      },
      "source": [
        "### Descargar datos\n",
        "\n",
        "Lo primero que tendremos que hacer es descargar el código con el modelo ya implementado y el set de datos que trabajaremos en esta ocación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CgQA4ApdgGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!gdown https://drive.google.com/a/uc.cl/uc?id=1OxmaqDCEPrzCHqo10P5FXZQ12AKik3e4\n",
        "!tar -xvf datos_practico_final_diplomado.tar.gz\n",
        "!mv diplomado/TF2nets.py .\n",
        "!mv diplomado/utils.py ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYOTFHvp-enL",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "**Actividad 1** ¿Cual es uno de los aporte que entrega los modelos de deep learning cuando se trabaja con imágenes? Comente en función de como antes era la metodología de trabajo cuando se utilizaban imágenes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NO-iAw_fj74",
        "colab_type": "text"
      },
      "source": [
        "**Respuesta**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "at4NnkoYX4Gi",
        "colab_type": "text"
      },
      "source": [
        "## Cargar librerías & datos\n",
        "\n",
        "Ya descargando los datos y archivos necesarios, continuaremos cargando todas las librerías necesarias para el laboratorio actual."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB4tViApR58k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import time\n",
        "import json\n",
        "import pickle\n",
        "from math import ceil\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from utils import load_embeddings_and_ids, concatenate_featmats, User, HybridScorer, VisualSimilarityHandler, VisualSimilarityHandler_ContentAndStyle, get_decaying_learning_rates, ground_truth_rank_indexes, auc_exact, plot_images, load_clusters, get_art_indexes_per_cluster\n",
        "import tensorflow as tf\n",
        "from TF2nets import TrainLogger, CuratorNet, train_loss_fn, test_acc_fn\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfiTcCZcVUvb",
        "colab_type": "text"
      },
      "source": [
        "Dentro del conjunto de datos descargados, se cuenta con los _embeddings_ de los items que fueron procesados anteriormente por nuestro equipo de super ayudantes. Recuerden que el _embedding_ de las imágenes consiste en procesar cada imagen por una Red Neuronal Convolucional (CNN), que en este caso tienen las arquitectura de ResNet50 y ResNext101.\n",
        "\n",
        "Para los interesados, les dejamos un par de links que pueden revisar:\n",
        "- [Review: ResNet — Winner of ILSVRC 2015 (Image Classification, Localization, Detection)](https://towardsdatascience.com/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8)\n",
        "- [Review: ResNeXt — 1st Runner Up in ILSVRC 2016 (Image Classification)](https://towardsdatascience.com/review-resnext-1st-runner-up-of-ilsvrc-2016-image-classification-15d7f17b42ac)\n",
        "\n",
        "Recuerden que extraer características visuales con una CNN nos quedamos con la representación vectorial de la última capa _fully connected_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iox3aQlPo4vK",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "**Actividad 2**: ¿Por qué el modelo requiere preprocesar las imágenes por una red CNN?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjpVZYgipF7Q",
        "colab_type": "text"
      },
      "source": [
        "**Respuesta**:\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5De-tGhVVd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet50 = load_embeddings_and_ids('diplomado/art/ResNet50/', 'flatten_1.npy', 'ids')\n",
        "resnext101 = load_embeddings_and_ids('diplomado/art/resnext101_32x8d_wsl/', 'features.npy', 'ids.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ML2AT5s81UF",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "**Actividad 3**: ¿Qué ventaja tiene cargar datos pre-entrenados?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFjoe8gfM-i-",
        "colab_type": "text"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjfaih8hM-Sx",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvW9DGpyVZiq",
        "colab_type": "text"
      },
      "source": [
        "###  Preprocesamiento de datos\n",
        "\n",
        "En esta sección haremos un preprocesamiento a los datos para que el modelo tenga un mejor desempeño.\n",
        "\n",
        "Al trabajar con modelos de deep learning, se recomienda normalizar los datos para que cada característica tenga media 0 y desviación estándard 1. Para ello, realizamos la siguiente operación:\n",
        "$x_i = \\frac{x_i - \\bar{x}}{std(x)}$\n",
        "\n",
        "Esta transformación (z-score) es aplicada a los _features_ finales que es el resultado de la concatenación de los _features_ de las arquitecturas ResNet50 y ResNext101.\n",
        "\n",
        "Además, asignamos a cada vector de imágenes un _cluster_ específico que luego utilizaremos al generar datos negativos (_negative sampling_)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQhh11PtVX38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_list = [resnet50, resnext101]\n",
        "\n",
        "artwork_ids_set = set()\n",
        "for embedding in embedding_list:\n",
        "    if len(artwork_ids_set) == 0:        \n",
        "        artwork_ids_set.update(embedding['index2id'])\n",
        "    else:\n",
        "        artwork_ids_set.intersection_update(embedding['index2id'])\n",
        "artwork_ids = list(artwork_ids_set)\n",
        "artwork_id2index = {_id:i for i,_id in enumerate(artwork_ids)}\n",
        "n_artworks = len(artwork_ids)\n",
        "\n",
        "featmat_list = [tmp['featmat'] for tmp in embedding_list]\n",
        "id2index_list = [tmp['id2index'] for tmp in embedding_list]\n",
        "concat_featmat = concatenate_featmats(artwork_ids, featmat_list, id2index_list)\n",
        "\n",
        "concat_featmat = StandardScaler().fit_transform(concat_featmat)\n",
        "\n",
        "cluster_ids, artId2clustId = load_clusters('diplomado/art/Clustering/artworkId2clusterId(resnet50+resnext101).json', n_artworks, artwork_id2index)\n",
        "n_clusters = len(set(cluster_ids))\n",
        "clustId2artIndexes = get_art_indexes_per_cluster(cluster_ids, n_clusters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiYVVIGnVvk1",
        "colab_type": "text"
      },
      "source": [
        "Para realizar análisis de similaridad cargaremos el vector característico de cada imágen transformado por un modelo PCA con 200 características principales.\n",
        "\n",
        "Es importante señalar que los vectores PCA200 sólo se utilizan para analizar los datos y no como _input_ del modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIi4jE_vVcYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca200 = load_embeddings_and_ids(\n",
        "    'diplomado/art/PCA200(resnet50+resnext101)/',\n",
        "    'embeddings.npy',\n",
        "    'ids.npy')\n",
        "\n",
        "\n",
        "pca200_embeddings = pca200['featmat']\n",
        "pca200_index2id = pca200['index2id']\n",
        "pca200_id2index = pca200['id2index']\n",
        "\n",
        "assert np.array_equal(artwork_ids, pca200_index2id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dko4nSAV9Brf",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "**Actividad 4**: ¿Cuál es la utilidad de PCA?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBvM5W9VM35k",
        "colab_type": "text"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfYBDZhCM3vC",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCkfB-jbVzmF",
        "colab_type": "text"
      },
      "source": [
        "A continuación cargaremos todos los datos relacionados a los usuarios y su respectivo comportamiento de compras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hrRqgj2Horl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "users = pickle.load(open('diplomado/art/users.pickle', 'rb'))\n",
        "n_users = pickle.load(open('diplomado/art/n_users.pickle', 'rb'))\n",
        "artist_ids = pickle.load(open('diplomado/art/artist_ids.pickle', 'rb'))\n",
        "artistId2artworkIndexes = pickle.load(open('diplomado/art/artistId2artworkIndexes.pickle', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfjj7a6JWLFO",
        "colab_type": "text"
      },
      "source": [
        "En la siguiente sección, se implementan funciones para generar los set de datos de entrenamiento. Tal como se revisó en clases, el modelo se entrena con una técnica llamada _Triplet Loss_, en la cual para cada par positivo (usuerio, ítem) buscaremos un ítem negativo, esto es, un ítem que el usuario nunca ha comprado. De esta forma, nuestro set de entrenamiento se compone de tripletas de la forma $(u, i^+, i^-)$, donde $u$ es el usuario, $i^+$ es el ejemplo positivo (que ha comprado) y $i^-$ es el ejemplo negativo (que no ha comprado)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYZzX73dVcNu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_MOD = 402653189\n",
        "_BASE = 92821\n",
        "\n",
        "\n",
        "def hash_triple(profile, pi, ni):\n",
        "    h = 0\n",
        "    for x in profile:\n",
        "        h = ((h * _BASE) % _MOD + x) % _MOD\n",
        "    h = ((h * _BASE) % _MOD + pi) % _MOD\n",
        "    h = ((h * _BASE) % _MOD + ni) % _MOD\n",
        "    return h\n",
        "\n",
        "\n",
        "def sanity_check_instance(instance, pos_in_profile=True, profile_set=None):\n",
        "    profile, pi, ni, ui = instance\n",
        "    try:\n",
        "        assert 0 <= pi < n_artworks\n",
        "        assert 0 <= ni < n_artworks\n",
        "        assert pi != ni        \n",
        "        assert not vissimhandler.same(pi,ni)\n",
        "        if ui == -1: return\n",
        "        \n",
        "        assert 0 <= ui < n_users\n",
        "        user = users[ui]\n",
        "        assert all(i in user.artwork_idxs_set for i in profile)\n",
        "        user_profile = user.artwork_idxs_set if profile_set is None else profile_set\n",
        "        assert ni not in user_profile\n",
        "        if pos_in_profile is not None:\n",
        "            assert (pi in user_profile) == pos_in_profile\n",
        "        spi = hybrid_scorer.get_score(ui, user.artwork_idxs, pi)\n",
        "        sni = hybrid_scorer.get_score(ui, user.artwork_idxs, ni)\n",
        "        assert spi > sni\n",
        "\n",
        "    except AssertionError:\n",
        "        print('profile = ', profile)\n",
        "        print('pi = ', pi)\n",
        "        print('ni = ', ni)\n",
        "        print('ui = ', ui)\n",
        "        raise\n",
        "\n",
        "\n",
        "def append_instance(container, instance, **kwargs):\n",
        "    global _hash_collisions\n",
        "    profile, pi, ni, ui = instance\n",
        "    \n",
        "    h = hash_triple(profile, pi, ni)\n",
        "    if h in used_hashes:\n",
        "        _hash_collisions += 1\n",
        "        return False\n",
        "    \n",
        "    if vissimhandler.same(pi, ni):\n",
        "        return False\n",
        "    \n",
        "    sanity_check_instance(instance, **kwargs)\n",
        "    container.append(instance)\n",
        "    used_hashes.add(h)\n",
        "    return True\n",
        "\n",
        "\n",
        "def print_triple(t):\n",
        "    profile, pi, ni, ui = t\n",
        "    print ('profile = ', [artwork_ids[i] for i in profile])\n",
        "    print ('pi = ', artwork_ids[pi])\n",
        "    print ('ni = ', artwork_ids[ni])\n",
        "    print ('ui = ', user_ids[ui] if ui != -1 else -1)\n",
        "\n",
        "\n",
        "def print_num_samples(sampler_func):\n",
        "    def wrapper(instances_container, n_samples):        \n",
        "        while True:\n",
        "            len_before = len(instances_container)\n",
        "            sampler_func(instances_container, n_samples)\n",
        "            actual_samples = len(instances_container) - len_before\n",
        "            delta = n_samples - actual_samples\n",
        "            print('  target samples: %d' % n_samples)\n",
        "            print('  actual samples: %d' % actual_samples)\n",
        "            print('  delta: %d' % (delta))\n",
        "            if delta <= 0: break\n",
        "            print('  ** delta > 0 -> sampling more instances again ...')\n",
        "            n_samples = delta\n",
        "    return wrapper\n",
        "\n",
        "def sample_artwork_index__outside_profile(\n",
        "        artists_list, clusters_list, profile_set):\n",
        "    while True:\n",
        "        if random.random() <= FINE_GRAINED_THRESHOLD:\n",
        "            if random.random() <= 0.5:\n",
        "                a = random.choice(artists_list)\n",
        "                i = random.choice(artistId2artworkIndexes[a])\n",
        "            else:\n",
        "                c = random.choice(clusters_list)\n",
        "                i = random.choice(clustId2artIndexes[c])\n",
        "        else:\n",
        "            c = random.randint(0, n_clusters-1)\n",
        "            i = random.choice(clustId2artIndexes[c])\n",
        "        if i not in profile_set: return i\n",
        "\n",
        "@print_num_samples\n",
        "def generate_samples__outside_profile__real_users(instances_container, n_samples):\n",
        "    n_samples_per_user = ceil(n_samples / n_users)\n",
        "    debug = 0\n",
        "    for ui, user in enumerate(users):        \n",
        "        profile = user.artwork_idxs\n",
        "        profile_set = user.artwork_idxs_set\n",
        "        artists_list = user.artist_ids\n",
        "        clusters_list = user.content_cluster_ids\n",
        "        n = n_samples_per_user\n",
        "        user_margin = CONFIDENCE_MARGIN / len(profile)\n",
        "        while n > 0:\n",
        "            pi = sample_artwork_index__outside_profile(artists_list, clusters_list, profile_set)\n",
        "            ni = sample_artwork_index__outside_profile(artists_list, clusters_list, profile_set)\n",
        "            if pi == ni: continue\n",
        "            pi_score = hybrid_scorer.get_score(ui, profile, pi)\n",
        "            ni_score = hybrid_scorer.get_score(ui, profile, ni)\n",
        "            if pi_score < ni_score:\n",
        "                pi_score, ni_score = ni_score, pi_score\n",
        "                pi, ni = ni, pi\n",
        "            if pi_score < ni_score + user_margin: continue\n",
        "            if append_instance(instances_container, (profile, pi, ni, ui),\n",
        "                               profile_set=profile_set, pos_in_profile=False):                \n",
        "                n -= 1\n",
        "                if n == 0 or debug % 1000 == 0:\n",
        "                    print('debug: user %d/%d : n=%d' % (ui, len(users), n), flush=True, end='\\r')\n",
        "                debug += 1\n",
        "\n",
        "\n",
        "FINE_GRAINED_THRESHOLD = 0.7\n",
        "ARTIST_BOOST = 0.2\n",
        "CONFIDENCE_MARGIN = 0.18\n",
        "\n",
        "vissimhandler = VisualSimilarityHandler(cluster_ids, pca200_embeddings)\n",
        "\n",
        "hybrid_scorer = HybridScorer(vissimhandler, artist_ids, artist_boost=ARTIST_BOOST)\n",
        "\n",
        "\n",
        "vissimhandler.count = 0\n",
        "used_hashes = set()\n",
        "_hash_collisions = 0\n",
        "train_instances = []\n",
        "test_instances = []\n",
        "\n",
        "TOTAL_SAMPLES__TRAIN = 50000\n",
        "TOTAL_SAMPLES__TEST =  TOTAL_SAMPLES__TRAIN * 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "al7XZCbypeCj",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "**Actividad 5**: Dado el preprocesamiento que se ha implementado hasta el momento, ¿qué tipo de sistema recomendador se implementará? Justifique su respuesta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPpsyLF5poue",
        "colab_type": "text"
      },
      "source": [
        "**Respuesta**:\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rz818RgZppLF",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "**Actividad 6** En base a la respuesta anterior, mencione una ventaja y desventaja del tipo de sistema recomendador que se implementará. Explique en detalle cada ventaja y desventaja."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJjY6adfps_X",
        "colab_type": "text"
      },
      "source": [
        "**Respuesta**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsidgjvaWRFg",
        "colab_type": "text"
      },
      "source": [
        "## Sampleo de Triplets para Rankear\n",
        "\n",
        "En esta sección utilizaremos las funciones descritas anteriormente para generar las tripletas necesarias para entrenar el modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnZSeUW5rMrG",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "**Actividad 7**: Explique brevemente en sus palabras cómo funciona el modelo de ranking _Curator Net_ (modelo implementado en este laboratorio)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aeVdwLtrM_k",
        "colab_type": "text"
      },
      "source": [
        "**Respuesta**:\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3xxWIS-VcLD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "print('=======================================\\nSampleando tuplas de entrenamiento...')\n",
        "generate_samples__outside_profile__real_users(train_instances, n_samples=TOTAL_SAMPLES__TRAIN)\n",
        "\n",
        "print('=======================================\\nSampleando tuplas de test...')\n",
        "generate_samples__outside_profile__real_users(test_instances, n_samples=TOTAL_SAMPLES__TEST)\n",
        "\n",
        "print(len(train_instances), len(test_instances))\n",
        "print('hash_collisions = ', _hash_collisions)\n",
        "print('visual_collisions = ', vissimhandler.count)\n",
        "\n",
        "random.shuffle(train_instances)\n",
        "train_instances.sort(key=lambda x: len(x[0]))\n",
        "test_instances.sort(key=lambda x: len(x[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO5n8toelUew",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "**Actividad 8**\n",
        "Explique con sus palabras cuál es el beneficio de utilizar sampleo de tripletas para entrenar la función de _ranking_. _Hint_: se revisó en clase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcGZlUzIlkiH",
        "colab_type": "text"
      },
      "source": [
        "**Respuesta**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4tSIGP1WnKt",
        "colab_type": "text"
      },
      "source": [
        "### Entrenamiento del modelo\n",
        "\n",
        "Ya teniendo todos los datos cargados y preprocesados, estamos en condiciones de entrenar nuestro modelo de _Deep Learning_."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RL8I5-hXWmnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_minibatches(tuples, max_users_items_per_batch):\n",
        "    ui_count = 0\n",
        "    offset = 0\n",
        "    \n",
        "    batch_ranges = []\n",
        "    for i, t in enumerate(tuples):\n",
        "        ui_count += len(t[0]) + 3\n",
        "        if ui_count > max_users_items_per_batch:\n",
        "            batch_ranges.append((offset, i))\n",
        "            ui_count = len(t[0]) + 3\n",
        "            offset = i\n",
        "            assert ui_count <= max_users_items_per_batch\n",
        "    assert offset < len(tuples)\n",
        "    batch_ranges.append((offset, len(tuples)))\n",
        "            \n",
        "    n_tuples = len(tuples)\n",
        "    n_batches = len(batch_ranges)\n",
        "    print('n_tuples = ', n_tuples)\n",
        "    print('n_batches = ', n_batches)\n",
        "    \n",
        "    assert batch_ranges[0][0] == 0\n",
        "    assert all(batch_ranges[i][1] == batch_ranges[i+1][0] for i in range(n_batches-1))\n",
        "    assert batch_ranges[-1][1] == n_tuples\n",
        "    assert sum(b[1] - b[0] for b in batch_ranges) == n_tuples\n",
        "    \n",
        "    profile_indexes_batches = [None] * n_batches\n",
        "    profile_size_batches = [None] * n_batches\n",
        "    positive_index_batches = [None] * n_batches\n",
        "    negative_index_batches = [None] * n_batches\n",
        "    \n",
        "    for i, (jmin, jmax) in enumerate(batch_ranges):\n",
        "        actual_batch_size = jmax - jmin\n",
        "        profile_maxlen = max(len(tuples[j][0]) for j in range(jmin, jmax))\n",
        "        profile_indexes_batch = np.full((actual_batch_size, profile_maxlen), 0, dtype=int)\n",
        "        profile_size_batch = np.empty((actual_batch_size,))\n",
        "        positive_index_batch = np.empty((actual_batch_size,), dtype=int)\n",
        "        negative_index_batch = np.empty((actual_batch_size,), dtype=int)\n",
        "        \n",
        "        for j in range(actual_batch_size):\n",
        "            # profile indexes\n",
        "            for k,v in enumerate(tuples[jmin+j][0]):\n",
        "                profile_indexes_batch[j][k] = v\n",
        "            # profile size\n",
        "            profile_size_batch[j] = len(tuples[jmin+j][0])        \n",
        "            # positive index\n",
        "            positive_index_batch[j] = tuples[jmin+j][1]\n",
        "            # negative index\n",
        "            negative_index_batch[j] = tuples[jmin+j][2]\n",
        "            \n",
        "        profile_indexes_batches[i] = profile_indexes_batch\n",
        "        profile_size_batches[i] = profile_size_batch\n",
        "        positive_index_batches[i] = positive_index_batch\n",
        "        negative_index_batches[i] = negative_index_batch\n",
        "        \n",
        "    return dict(\n",
        "        profile_indexes_batches = profile_indexes_batches,\n",
        "        profile_size_batches    = profile_size_batches,\n",
        "        positive_index_batches  = positive_index_batches,\n",
        "        negative_index_batches  = negative_index_batches,\n",
        "        n_batches               = n_batches,\n",
        "    )\n",
        "\n",
        "\n",
        "def sanity_check_minibatches(minibatches):\n",
        "    profile_indexes_batches = minibatches['profile_indexes_batches']\n",
        "    profile_size_batches = minibatches['profile_size_batches']\n",
        "    positive_index_batches = minibatches['positive_index_batches']\n",
        "    negative_index_batches = minibatches['negative_index_batches']\n",
        "    n_batches = minibatches['n_batches']\n",
        "    assert n_batches == len(profile_indexes_batches)\n",
        "    assert n_batches == len(profile_size_batches)\n",
        "    assert n_batches == len(positive_index_batches)\n",
        "    assert n_batches == len(negative_index_batches)\n",
        "    assert n_batches > 0\n",
        "    \n",
        "    for profile_indexes, profile_size, positive_index, negative_index in zip(\n",
        "        profile_indexes_batches,\n",
        "        profile_size_batches,\n",
        "        positive_index_batches,\n",
        "        negative_index_batches\n",
        "    ):\n",
        "        n = profile_size.shape[0]\n",
        "        assert n == profile_indexes.shape[0]\n",
        "        assert n == positive_index.shape[0]\n",
        "        assert n == negative_index.shape[0]\n",
        "        \n",
        "        for i in range(n):\n",
        "            assert positive_index[i] != negative_index[i]\n",
        "            psz = int(profile_size[i])\n",
        "            m = profile_indexes[i].shape[0]\n",
        "            assert psz <= m\n",
        "            for j in range(psz, m):\n",
        "                assert profile_indexes[i][j] == 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owLwVzUw9uXV",
        "colab_type": "text"
      },
      "source": [
        "Como este modelo no es de clasificación o regresión, el error que vamos a calcular para optimizar es distinto. Es por eso que creamos nuestra propia forma de calcular el error, la cual está contenida en la función `train_loss_fn` y que es llamada dentro de la función `train_step`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JT4R9vce9sY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_step(model, opt, x, embs):\n",
        "    with tf.GradientTape() as tape:\n",
        "        uv, pv, nv = model(x, embs)\n",
        "        loss = train_loss_fn((uv, pv, nv), model)\n",
        "    grads = tape.gradient(loss, model.trainable_weights)\n",
        "    opt.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDgE5EQcLU4i",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "**Actividad 9:** Explique qué busca el modelo cuando procesa el embedding de usuario y de ítems. _Hint_: La respuesta está en interpretar la función de pérdida correctamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55aztQVELb7d",
        "colab_type": "text"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R39Ewk1PLbT4",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtuUkGsAnwoG",
        "colab_type": "text"
      },
      "source": [
        "En las celdas que siguen, se implementan las funciones necesarias para entrenar el modelo. La función `train_loop` implementa lo que sucede en cada paso del descenso de gradiente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QH0F2JwVcGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_loop(model, opt, train_mb, test_mb, patience=3, **kwargs):\n",
        "\n",
        "    # ========= CHECKPOINTING ============\n",
        "    trainlogger = TrainLogger(kwargs['model_path'] + 'train_logs.csv')\n",
        "    ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=model)\n",
        "    manager = tf.train.CheckpointManager(ckpt, kwargs['model_path'], max_to_keep=3)\n",
        "    ckpt.restore(manager.latest_checkpoint)\n",
        "\n",
        "    if manager.latest_checkpoint:\n",
        "        print(\"Modelo restaurado de {}\".format(manager.latest_checkpoint))\n",
        "    else:\n",
        "        print(\"Modelo inicializado desde cero.\")\n",
        "\n",
        "    # ========= PREPARATIONS ============\n",
        "    initial_test_acc = 0.\n",
        "    for profile_indexes, positive_index, negative_index in zip(test_mb['profile_indexes_batches'],\n",
        "                                                               test_mb['positive_index_batches'],\n",
        "                                                               test_mb['negative_index_batches']):\n",
        "        uv, pv, nv = model((profile_indexes, positive_index, negative_index), kwargs['pretrained_embeddings'])\n",
        "        minibatch_test_acc = test_acc_fn((uv, pv, nv))\n",
        "        initial_test_acc += minibatch_test_acc\n",
        "\n",
        "    initial_test_acc /= kwargs['n_test_instances']\n",
        "    print(\"Antes de entrenar: test_accuracy = {}\".format(initial_test_acc))\n",
        "\n",
        "    best_test_acc = initial_test_acc\n",
        "    seconds_training = 0\n",
        "    elapsed_seconds_from_last_check = 0\n",
        "    checks_with_no_improvement = 0\n",
        "\n",
        "    # ========= TRAINING ============\n",
        "    print('Entrenamiento iniciado...')\n",
        "\n",
        "    while seconds_training < kwargs['max_seconds_training']:\n",
        "\n",
        "        for train_i, (profile_indexes,  positive_index, negative_index) in enumerate(zip(\n",
        "                train_mb['profile_indexes_batches'],\n",
        "                train_mb['positive_index_batches'],\n",
        "                train_mb['negative_index_batches'])):\n",
        "\n",
        "            # optimize and get training loss\n",
        "            start_t = time.time()\n",
        "            minibatch_train_loss = train_step(model, opt, (profile_indexes, positive_index, negative_index), kwargs['pretrained_embeddings'])\n",
        "            delta_t = time.time() - start_t\n",
        "\n",
        "            if train_i % 10 == 0:\n",
        "                print('Batch training loss: {}'.format(float(minibatch_train_loss)))\n",
        "\n",
        "            # update time tracking variables\n",
        "            seconds_training += delta_t\n",
        "            elapsed_seconds_from_last_check += delta_t\n",
        "\n",
        "            # check for improvements using test set if it's time to do so\n",
        "            if elapsed_seconds_from_last_check >= kwargs['min_seconds_to_check_improvement']:\n",
        "\n",
        "                # --- testing\n",
        "                test_acc = 0.\n",
        "                for test_profile_indexes, test_positive_index, test_negative_index in zip(\n",
        "                        test_mb['profile_indexes_batches'],\n",
        "                        test_mb['positive_index_batches'],\n",
        "                        test_mb['negative_index_batches'] ):\n",
        "                    tuv, tpv, tnv = model((test_profile_indexes, test_positive_index, test_negative_index), kwargs['pretrained_embeddings'])\n",
        "                    minibatch_test_acc = test_acc_fn((tuv, tpv, tnv))\n",
        "                    test_acc += minibatch_test_acc\n",
        "                test_acc /= kwargs['n_test_instances']\n",
        "\n",
        "                print((\"[Checkpoint] test_accuracy = %.7f,\"\n",
        "                       \" check_secs = %.2f, total_secs = %.2f\") % (\n",
        "                          test_acc, elapsed_seconds_from_last_check, seconds_training))\n",
        "\n",
        "                # check for improvements\n",
        "                if test_acc > best_test_acc:\n",
        "                    best_test_acc = test_acc\n",
        "                    checks_with_no_improvement = 0\n",
        "                    save_path = manager.save()\n",
        "                    print(\"   ** Mejora detectada: modelo guardado en \", save_path)\n",
        "                    model_updated = True\n",
        "                else:\n",
        "                    checks_with_no_improvement += 1\n",
        "                    model_updated = False\n",
        "\n",
        "                # --- logging ---\n",
        "                trainlogger.log_update(minibatch_train_loss,\n",
        "                    test_acc, kwargs['n_train_instances'], kwargs['n_test_instances'],\n",
        "                    elapsed_seconds_from_last_check, kwargs['batch_size'], opt.learning_rate.numpy(),\n",
        "                    't' if model_updated else 'f')\n",
        "\n",
        "                if checks_with_no_improvement > patience:\n",
        "                    print('=== EARLY STOPPING ===')\n",
        "                    return None\n",
        "                # --- reset check variables\n",
        "                elapsed_seconds_from_last_check = 0\n",
        "    print('====== TIMEOUT. ======')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a0GDXSqVcDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_network(train_minibatches, test_minibatches,\n",
        "                  n_train_instances, n_test_instances, batch_size,\n",
        "                  pretrained_embeddings,\n",
        "                  user_layer_units,\n",
        "                  item_layer_units,\n",
        "                  model_path,\n",
        "                  max_seconds_training=3600,\n",
        "                  min_seconds_to_check_improvement=60,\n",
        "                  patience=3):\n",
        "\n",
        "    model = CuratorNet(\n",
        "        pretrained_embedding_dim=pretrained_embeddings.shape[1],\n",
        "        user_layer_units=user_layer_units,\n",
        "        item_layer_units=item_layer_units\n",
        "    )\n",
        "\n",
        "    opt = tf.keras.optimizers.Adam()\n",
        "\n",
        "    model.compile(optimizer=opt,\n",
        "                  loss=None,\n",
        "                  metrics=None)\n",
        "\n",
        "    train_loop(model, opt,\n",
        "               train_minibatches,\n",
        "               test_minibatches,\n",
        "               pretrained_embeddings=pretrained_embeddings,\n",
        "               model_path=model_path,\n",
        "               n_test_instances=n_test_instances,\n",
        "               max_seconds_training=max_seconds_training,\n",
        "               min_seconds_to_check_improvement=min_seconds_to_check_improvement,\n",
        "               n_train_instances=n_train_instances,\n",
        "               batch_size=batch_size,\n",
        "               patience=patience)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIqQCEn89a0f",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "**Actividad 10**: Cuando se compila el modelo, ¿por qué no se le entrega una función de perdida? y ¿qué optimizador estamos ocupando?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq7faaQbLm28",
        "colab_type": "text"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWi2HnBiLmyV",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKRxGNnjVcA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_minibatches = generate_minibatches(train_instances, max_users_items_per_batch=600*10)\n",
        "sanity_check_minibatches(train_minibatches)\n",
        "\n",
        "test_minibatches = generate_minibatches(test_instances, max_users_items_per_batch=600*10)\n",
        "sanity_check_minibatches(test_minibatches)\n",
        "\n",
        "avg_train_batch_size = ceil(np.mean([b.shape[0] for b in train_minibatches['profile_indexes_batches']]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXVHmAUgnD9t",
        "colab_type": "text"
      },
      "source": [
        "En la siguiente celda, entrenaremos un modelo creado inicialmente con parámetros aleatorios, al igual que los modelos revisados en clases.\n",
        "\n",
        "Podemos revisar cómo la métrica _accuracy_ aumenta luego de entrenar el modelo con algunos datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "087WaF0iWxri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "MODEL_PATH = 'modelo_diplomado'\n",
        "\n",
        "MINUTES = 1\n",
        "train_network(train_minibatches, test_minibatches,\n",
        "              len(train_instances), len(test_instances),\n",
        "              batch_size=avg_train_batch_size,\n",
        "              pretrained_embeddings=concat_featmat,\n",
        "              user_layer_units=[300, 300, 200],\n",
        "              item_layer_units=[200, 200],\n",
        "              model_path=MODEL_PATH,\n",
        "              max_seconds_training=60*MINUTES,\n",
        "              min_seconds_to_check_improvement=60*1,\n",
        "              patience=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pgwh85R2W3_f",
        "colab_type": "text"
      },
      "source": [
        "## Evaluación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PuOm94RoHQJ",
        "colab_type": "text"
      },
      "source": [
        "Teniendo nuestro modelo y entrenado, continuaremos con la evaluación de nuestro modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GSWAq5SWxlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_aucs_and_topk_recommendations(model_path, train_test_list, K=10, num_users=10):\n",
        "    resnet50 = load_embeddings_and_ids('diplomado/art/ResNet50/', 'flatten_1.npy', 'ids')\n",
        "    resnext101 = load_embeddings_and_ids('diplomado/art/resnext101_32x8d_wsl/', 'features.npy', 'ids.npy')\n",
        "    embedding_list = [resnet50, resnext101]\n",
        "\n",
        "    artwork_ids_set = set()\n",
        "    for embedding in embedding_list:\n",
        "        if len(artwork_ids_set) == 0:\n",
        "            artwork_ids_set.update(embedding['index2id'])\n",
        "        else:\n",
        "            artwork_ids_set.intersection_update(embedding['index2id'])\n",
        "    artwork_ids = list(artwork_ids_set)\n",
        "    artwork_id2index = {_id: i for i, _id in enumerate(artwork_ids)}\n",
        "    n_artworks = len(artwork_ids)\n",
        "\n",
        "    featmat_list = [tmp['featmat'] for tmp in embedding_list]\n",
        "    id2index_list = [tmp['id2index'] for tmp in embedding_list]\n",
        "    concat_featmat = concatenate_featmats(artwork_ids, featmat_list, id2index_list)\n",
        "\n",
        "    embeddings = StandardScaler().fit_transform(concat_featmat)\n",
        "\n",
        "    all_indexes = list(range(n_artworks))\n",
        "    recommendations = []\n",
        "\n",
        "    model = CuratorNet(pretrained_embedding_dim=embeddings.shape[1],\n",
        "                       user_layer_units=[300, 300, 200],\n",
        "                       item_layer_units=[200, 200])\n",
        "\n",
        "    opt = tf.keras.optimizers.Adam(clipnorm=0.1)\n",
        "    model.compile(optimizer=opt,\n",
        "                  loss=None,\n",
        "                  metrics=None)\n",
        "\n",
        "    ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=model)\n",
        "    manager = tf.train.CheckpointManager(ckpt, model_path, max_to_keep=3)\n",
        "    ckpt.restore(manager.latest_checkpoint).expect_partial()\n",
        "\n",
        "    aucs = []\n",
        "    for row in tqdm(train_test_list[:num_users]):\n",
        "        train_indexes = np.array([artwork_id2index[_id] for _id in row['train']])\n",
        "        test_indexes_set = set(artwork_id2index[_id] for _id in row['test'])\n",
        "        train_indexes_set = set(train_indexes)\n",
        "        candidate_indexes = np.array([i for i in all_indexes if i not in train_indexes_set])\n",
        "\n",
        "        user_score, candidates_score, _ = model((np.expand_dims(train_indexes, axis=0),\n",
        "                                                 np.expand_dims(candidate_indexes, axis=0),\n",
        "                                                 np.expand_dims(candidate_indexes, axis=0)),\n",
        "                                                embeddings)\n",
        "\n",
        "        u_score = user_score\n",
        "        candidates_score = np.squeeze(candidates_score)\n",
        "        result = tf.squeeze(tf.matmul(u_score, tf.transpose(candidates_score)))\n",
        "\n",
        "        tuples = [(s, i) for i, s in zip(candidate_indexes, result)]\n",
        "        tuples.sort(reverse=True)\n",
        "\n",
        "        ranked_candidate_indexes = [t[1] for t in tuples]\n",
        "        gt_indexes = ground_truth_rank_indexes(ranked_candidate_indexes, test_indexes_set)\n",
        "        auc = auc_exact(gt_indexes, len(candidate_indexes))\n",
        "        aucs.append(auc)\n",
        "        recommendations.append([artwork_ids[idx] for i, idx in enumerate(ranked_candidate_indexes) if i < K])\n",
        "\n",
        "        print(\"AUC: {:4f} ; AVG: {:4f}\".format(auc, sum(aucs) / len(aucs)))\n",
        "\n",
        "    return aucs, recommendations\n",
        "\n",
        "\n",
        "def visualize_recommendation(train_test, recommendations, aucs, images_path='diplomado/images', image_cache=dict(), topk=10):\n",
        "    pairs = [(auc, i) for i, auc in enumerate(aucs)]\n",
        "    pairs.sort(reverse=True)\n",
        "    for j in range(len(pairs)):\n",
        "        i = pairs[j][1]\n",
        "        print(\"\\nauc = %f\" % pairs[j][0])\n",
        "        print(\"-------- ENTRENAMIENTO (%d) ----------\" % len(train_test[i]['train']))\n",
        "        plot_images(plt, image_cache, train_test[i]['train'], images_path=images_path)\n",
        "        print(\"-------- RECOMENDACION (%d) ----------\" % topk)\n",
        "        plot_images(plt, image_cache, recommendations[i][:topk], images_path=images_path)\n",
        "        print(\"-------- DATOS REALES  (%d) ----------\" % len(train_test[i]['test']))\n",
        "        plot_images(plt, image_cache, train_test[i]['test'], images_path=images_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwjYZ7OtXHUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = json.load(open('diplomado/test.json'))\n",
        "print('Nº usuarios de test:', len(test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW2k4yzVWxom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EVAL_MODEL_PATH = 'diplomado/modelo_preentrenado_diplomado'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-yhB_3OtBzh",
        "colab_type": "text"
      },
      "source": [
        "La celda de a continuación puede tomar unos minutos en ejecutarse."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oheQTzFCWxg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "aucs, recommendations = get_aucs_and_topk_recommendations(EVAL_MODEL_PATH, test)\n",
        "print(\"AUC Final: {:4f}\".format(sum(aucs) / len(aucs)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ubdoq1F_HZz",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "**Actividad 11:** Cuando evaluamos estamos calculando el AUC, ¿qué otra métrica sería de utilidad calcular en este problema?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCX7KXHgb0U7",
        "colab_type": "text"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ISEC3iMb0Pu",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR6SElOTb7Nh",
        "colab_type": "text"
      },
      "source": [
        "### Ver recomendaciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "057qEHCtoW6V",
        "colab_type": "text"
      },
      "source": [
        "Por último analizaremos cualitativamente qué está recomendando el modelo, analizando el historial de compras del usuario.\n",
        "\n",
        "La sección marcada con \"ENTRENAMIENTO\" muestra el historial de compras de un usuario, mientras que la sección \"RECOMENDACION\" muestra los primero 10 ítems recomendados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D07xhHL7qKjy",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "**Actividad 12**: Además de la visualización que se realiza en esta sección, mencione qué otro uso se le podría dar a los embeddings de usuario o ítems que genera el modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psx-zEhyqNoN",
        "colab_type": "text"
      },
      "source": [
        "**Respuesta**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKt-4C15Wxef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualize_recommendation(test[:10], recommendations, aucs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KeDI2V_b-rl",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "**Actividad 13:** ¿Qué le parecen las recomendaciones con respecto a los ítems consumidos por los usuarios? **Comente en relación al contenido de las imágenes entregadas: como color, tema, que se muestra, estilo de dibujo, tipo de trazo, etc**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOHF-SiQckZH",
        "colab_type": "text"
      },
      "source": [
        "**Respuesta:**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkAmjfRfqc-f",
        "colab_type": "text"
      },
      "source": [
        "**Actividad 14** \n",
        "El dueño de TuGalería, don Galería, cuenta con información geográfica de sus clientes y cada ubicación está catalogada como ciudad, bosque, playa, etc. Don Galería, \n",
        "le pide a Ud. que incorpore la información de la ubicación en las recomendaciones. Elabore una propuesta conceptual."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCuB5hQPqkYv",
        "colab_type": "text"
      },
      "source": [
        "**Respuesta**:\n",
        "\n",
        "---"
      ]
    }
  ]
}